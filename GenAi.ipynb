{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d34e2a6b71c54b258185cbb8b474c40c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f6a6704c2c946c8961dccbcbbe0800f","IPY_MODEL_d1fdf30c4b894b3b9548a60e2b204e89","IPY_MODEL_bd7fee9de8bf41bfb64637b083dda646"],"layout":"IPY_MODEL_8eb4d741cd154124ad27ac4695aede1b"}},"5f6a6704c2c946c8961dccbcbbe0800f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0996593335274d09811d6a1f52d219bf","placeholder":"​","style":"IPY_MODEL_b00cc0759c904e41a7775696d6e81368","value":"100%"}},"d1fdf30c4b894b3b9548a60e2b204e89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c118ad61c494600b793e3b12956cb8e","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45b79ce04b194e66adc76ae0b72af34e","value":3}},"bd7fee9de8bf41bfb64637b083dda646":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31d0bf5748d7441c92d8604881012a79","placeholder":"​","style":"IPY_MODEL_230830b30b444988a01fc34c172e95fb","value":" 3/3 [00:00&lt;00:00,  7.46it/s]"}},"8eb4d741cd154124ad27ac4695aede1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0996593335274d09811d6a1f52d219bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b00cc0759c904e41a7775696d6e81368":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c118ad61c494600b793e3b12956cb8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45b79ce04b194e66adc76ae0b72af34e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31d0bf5748d7441c92d8604881012a79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"230830b30b444988a01fc34c172e95fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzBnDJzlzC8y","executionInfo":{"status":"ok","timestamp":1715251530059,"user_tz":-330,"elapsed":40725,"user":{"displayName":"Rishita Ojha","userId":"08520112917320238697"}},"outputId":"600f8220-defb-412a-fb00-7491cbbe7fb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["%pip install --upgrade pip\n","%pip install --disable-pip-version-check \\\n","    torch==1.13.1 \\\n","    torchdata==0.5.1 --quiet\n","\n","%pip install \\\n","    transformers==4.27.2 \\\n","    datasets==2.11.0  --quiet"]},{"cell_type":"code","source":["from datasets import load_dataset\n","from transformers import AutoModelForSeq2SeqLM\n","from transformers import AutoTokenizer\n","from transformers import GenerationConfig"],"metadata":{"id":"fYBQ6uhr0Bdy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["huggingface_dataset_name = \"knkarthick/dialogsum\"\n","\n","dataset = load_dataset(huggingface_dataset_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191,"referenced_widgets":["d34e2a6b71c54b258185cbb8b474c40c","5f6a6704c2c946c8961dccbcbbe0800f","d1fdf30c4b894b3b9548a60e2b204e89","bd7fee9de8bf41bfb64637b083dda646","8eb4d741cd154124ad27ac4695aede1b","0996593335274d09811d6a1f52d219bf","b00cc0759c904e41a7775696d6e81368","5c118ad61c494600b793e3b12956cb8e","45b79ce04b194e66adc76ae0b72af34e","31d0bf5748d7441c92d8604881012a79","230830b30b444988a01fc34c172e95fb"]},"id":"wGvO4mvX0NBu","executionInfo":{"status":"ok","timestamp":1715251639119,"user_tz":-330,"elapsed":3855,"user":{"displayName":"Rishita Ojha","userId":"08520112917320238697"}},"outputId":"0fbb4ea5-2f77-4ea7-9743-a11afb9f8417"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-cd36827d3490488d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d34e2a6b71c54b258185cbb8b474c40c"}},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"0doYoDwC4fbJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Summarize text without Prompt Engineering**"],"metadata":{"id":"lQWhh-ENEMwT"}},{"cell_type":"code","source":["example_indices = [40, 200]\n","\n","dash_line = '-'.join('' for x in range(100))\n","\n","for i, index in enumerate(example_indices):\n","    print(dash_line)\n","    print('Example ', i + 1)\n","    print(dash_line)\n","    print('INPUT DIALOGUE:')\n","    print(dataset['test'][index]['dialogue'])\n","    print(dash_line)\n","    print('BASELINE HUMAN SUMMARY:')\n","    print(dataset['test'][index]['summary'])\n","    print(dash_line)\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KIc3GO3Q0S_U","executionInfo":{"status":"ok","timestamp":1715251645971,"user_tz":-330,"elapsed":385,"user":{"displayName":"Rishita Ojha","userId":"08520112917320238697"}},"outputId":"c2a08550-36ae-48f8-833e-71ccd4a1ee2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------------------------\n","Example  1\n","---------------------------------------------------------------------------------------------------\n","INPUT DIALOGUE:\n","#Person1#: What time is it, Tom?\n","#Person2#: Just a minute. It's ten to nine by my watch.\n","#Person1#: Is it? I had no idea it was so late. I must be off now.\n","#Person2#: What's the hurry?\n","#Person1#: I must catch the nine-thirty train.\n","#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n","---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n","---------------------------------------------------------------------------------------------------\n","\n","---------------------------------------------------------------------------------------------------\n","Example  2\n","---------------------------------------------------------------------------------------------------\n","INPUT DIALOGUE:\n","#Person1#: Have you considered upgrading your system?\n","#Person2#: Yes, but I'm not sure what exactly I would need.\n","#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n","#Person2#: That would be a definite bonus.\n","#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n","#Person2#: How can we do that?\n","#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n","#Person2#: No.\n","#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n","#Person2#: That sounds great. Thanks.\n","---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n","---------------------------------------------------------------------------------------------------\n","\n"]}]},{"cell_type":"code","source":["model_name='google/flan-t5-base'\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"],"metadata":{"id":"JZYZN36g0bkL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"],"metadata":{"id":"uXebTgt20g7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentence = \"What time is it, Tom?\"\n","\n","sentence_encoded = tokenizer(sentence, return_tensors='pt')\n","\n","sentence_decoded = tokenizer.decode(\n","        sentence_encoded[\"input_ids\"][0],\n","        skip_special_tokens=True\n","    )\n","\n","print('ENCODED SENTENCE:')\n","print(sentence_encoded[\"input_ids\"][0])\n","print('\\nDECODED SENTENCE:')\n","print(sentence_decoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CReGnRHd0kVi","executionInfo":{"status":"ok","timestamp":1715251664637,"user_tz":-330,"elapsed":389,"user":{"displayName":"Rishita Ojha","userId":"08520112917320238697"}},"outputId":"63417add-cde3-4046-a102-4fc321c6c075"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ENCODED SENTENCE:\n","tensor([ 363,   97,   19,   34,    6, 3059,   58,    1])\n","\n","DECODED SENTENCE:\n","What time is it, Tom?\n"]}]},{"cell_type":"code","source":["for i, index in enumerate(example_indices):\n","    dialogue = dataset['test'][index]['dialogue']\n","    summary = dataset['test'][index]['summary']\n","\n","    inputs = tokenizer(dialogue, return_tensors='pt')\n","    output = tokenizer.decode(\n","        model.generate(\n","            inputs[\"input_ids\"],\n","            max_new_tokens=50,\n","        )[0],\n","        skip_special_tokens=True\n","    )\n","\n","    print(dash_line)\n","    print('Example ', i + 1)\n","    print(dash_line)\n","    print(f'INPUT PROMPT:\\n{dialogue}')\n","    print(dash_line)\n","    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n","    print(dash_line)\n","    print(f'MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\\n{output}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxUKRQbT0qiU","executionInfo":{"status":"ok","timestamp":1715251670592,"user_tz":-330,"elapsed":4120,"user":{"displayName":"Rishita Ojha","userId":"08520112917320238697"}},"outputId":"1157d352-3b89-477a-d500-cd90c46fedf0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------------------------\n","Example  1\n","---------------------------------------------------------------------------------------------------\n","INPUT PROMPT:\n","#Person1#: What time is it, Tom?\n","#Person2#: Just a minute. It's ten to nine by my watch.\n","#Person1#: Is it? I had no idea it was so late. I must be off now.\n","#Person2#: What's the hurry?\n","#Person1#: I must catch the nine-thirty train.\n","#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n","---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n","---------------------------------------------------------------------------------------------------\n","MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n","Person1: It's ten to nine.\n","\n","---------------------------------------------------------------------------------------------------\n","Example  2\n","---------------------------------------------------------------------------------------------------\n","INPUT PROMPT:\n","#Person1#: Have you considered upgrading your system?\n","#Person2#: Yes, but I'm not sure what exactly I would need.\n","#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n","#Person2#: That would be a definite bonus.\n","#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n","#Person2#: How can we do that?\n","#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n","#Person2#: No.\n","#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n","#Person2#: That sounds great. Thanks.\n","---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n","---------------------------------------------------------------------------------------------------\n","MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n","#Person1#: I'm thinking of upgrading my computer.\n","\n"]}]},{"cell_type":"markdown","source":["**Summarize Dialogue with an Instruction Prompt**"],"metadata":{"id":"_kGwtNElEZpX"}},{"cell_type":"code","source":["for i, index in enumerate(example_indices):\n","    dialogue = dataset['test'][index]['dialogue']\n","    summary = dataset['test'][index]['summary']\n","\n","    prompt = f\"\"\"\n","Summarize the following conversation.\n","\n","{dialogue}\n","\n","Summary:\n","    \"\"\"\n","\n","    # Input constructed prompt instead of the dialogue.\n","    inputs = tokenizer(prompt, return_tensors='pt')\n","    output = tokenizer.decode(\n","        model.generate(\n","            inputs[\"input_ids\"],\n","            max_new_tokens=50,\n","        )[0],\n","        skip_special_tokens=True\n","    )\n","\n","    print(dash_line)\n","    print('Example ', i + 1)\n","    print(dash_line)\n","    print(f'INPUT PROMPT:\\n{prompt}')\n","    print(dash_line)\n","    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n","    print(dash_line)\n","    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMujpS2c00Qh","executionInfo":{"status":"ok","timestamp":1715251677081,"user_tz":-330,"elapsed":4137,"user":{"displayName":"Rishita Ojha","userId":"08520112917320238697"}},"outputId":"a0018c65-6c97-4ee3-e8d7-3f086cc2f1a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------------------------\n","Example  1\n","---------------------------------------------------------------------------------------------------\n","INPUT PROMPT:\n","\n","Summarize the following conversation.\n","\n","#Person1#: What time is it, Tom?\n","#Person2#: Just a minute. It's ten to nine by my watch.\n","#Person1#: Is it? I had no idea it was so late. I must be off now.\n","#Person2#: What's the hurry?\n","#Person1#: I must catch the nine-thirty train.\n","#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n","\n","Summary:\n","    \n","---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n","---------------------------------------------------------------------------------------------------\n","MODEL GENERATION - ZERO SHOT:\n","The train is about to leave.\n","\n","---------------------------------------------------------------------------------------------------\n","Example  2\n","---------------------------------------------------------------------------------------------------\n","INPUT PROMPT:\n","\n","Summarize the following conversation.\n","\n","#Person1#: Have you considered upgrading your system?\n","#Person2#: Yes, but I'm not sure what exactly I would need.\n","#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n","#Person2#: That would be a definite bonus.\n","#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n","#Person2#: How can we do that?\n","#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n","#Person2#: No.\n","#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n","#Person2#: That sounds great. Thanks.\n","\n","Summary:\n","    \n","---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n","---------------------------------------------------------------------------------------------------\n","MODEL GENERATION - ZERO SHOT:\n","#Person1#: I'm thinking of upgrading my computer.\n","\n"]}]},{"cell_type":"markdown","source":["**Zero Shot Inference with the Prompt Template from FLAN-T5**\n","\n","---\n","\n"],"metadata":{"id":"vwS0-wQ9EfuD"}},{"cell_type":"code","source":["for i, index in enumerate(example_indices):\n","    dialogue = dataset['test'][index]['dialogue']\n","    summary = dataset['test'][index]['summary']\n","\n","    prompt = f\"\"\"\n","Dialogue:\n","\n","{dialogue}\n","\n","What was going on?\n","\"\"\"\n","\n","    inputs = tokenizer(prompt, return_tensors='pt')\n","    output = tokenizer.decode(\n","        model.generate(\n","            inputs[\"input_ids\"],\n","            max_new_tokens=50,\n","        )[0],\n","        skip_special_tokens=True\n","    )\n","\n","    print(dash_line)\n","    print('Example ', i + 1)\n","    print(dash_line)\n","    print(f'INPUT PROMPT:\\n{prompt}')\n","    print(dash_line)\n","    print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n","    print(dash_line)\n","    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mr5leq7Z07f4","executionInfo":{"status":"ok","timestamp":1715251686066,"user_tz":-330,"elapsed":5961,"user":{"displayName":"Rishita Ojha","userId":"08520112917320238697"}},"outputId":"af563d92-928b-437b-b0f0-a0149ddc5154"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------------------------\n","Example  1\n","---------------------------------------------------------------------------------------------------\n","INPUT PROMPT:\n","\n","Dialogue:\n","\n","#Person1#: What time is it, Tom?\n","#Person2#: Just a minute. It's ten to nine by my watch.\n","#Person1#: Is it? I had no idea it was so late. I must be off now.\n","#Person2#: What's the hurry?\n","#Person1#: I must catch the nine-thirty train.\n","#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n","\n","What was going on?\n","\n","---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n","\n","---------------------------------------------------------------------------------------------------\n","MODEL GENERATION - ZERO SHOT:\n","Tom is late for the train.\n","\n","---------------------------------------------------------------------------------------------------\n","Example  2\n","---------------------------------------------------------------------------------------------------\n","INPUT PROMPT:\n","\n","Dialogue:\n","\n","#Person1#: Have you considered upgrading your system?\n","#Person2#: Yes, but I'm not sure what exactly I would need.\n","#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n","#Person2#: That would be a definite bonus.\n","#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n","#Person2#: How can we do that?\n","#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n","#Person2#: No.\n","#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n","#Person2#: That sounds great. Thanks.\n","\n","What was going on?\n","\n","---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n","\n","---------------------------------------------------------------------------------------------------\n","MODEL GENERATION - ZERO SHOT:\n","#Person1#: You could add a painting program to your software. #Person2#: That would be a bonus. #Person1#: You might also want to upgrade your hardware. #Person1#\n","\n"]}]},{"cell_type":"markdown","source":["**One shot inference**"],"metadata":{"id":"3MfwCEKrE1gS"}},{"cell_type":"code","source":["def make_prompt(example_indices_full, example_index_to_summarize):\n","    prompt = ''\n","    for index in example_indices_full:\n","        dialogue = dataset['test'][index]['dialogue']\n","        summary = dataset['test'][index]['summary']\n","\n","        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n","        prompt += f\"\"\"\n","Dialogue:\n","\n","{dialogue}\n","\n","What was going on?\n","{summary}\n","\n","\n","\"\"\"\n","\n","    dialogue = dataset['test'][example_index_to_summarize]['dialogue']\n","\n","    prompt += f\"\"\"\n","Dialogue:\n","\n","{dialogue}\n","\n","What was going on?\n","\"\"\"\n","\n","    return prompt"],"metadata":{"id":"ex5yB2iX1A7r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_indices_full = [40]\n","example_index_to_summarize = 200\n","\n","one_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n","\n","print(one_shot_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nxMFwB3Q1GFR","executionInfo":{"status":"ok","timestamp":1715251690503,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rishita Ojha","userId":"08520112917320238697"}},"outputId":"0e2ee8f0-5376-4341-8c26-bf7cc3008b8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Dialogue:\n","\n","#Person1#: What time is it, Tom?\n","#Person2#: Just a minute. It's ten to nine by my watch.\n","#Person1#: Is it? I had no idea it was so late. I must be off now.\n","#Person2#: What's the hurry?\n","#Person1#: I must catch the nine-thirty train.\n","#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n","\n","What was going on?\n","#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n","\n","\n","\n","Dialogue:\n","\n","#Person1#: Have you considered upgrading your system?\n","#Person2#: Yes, but I'm not sure what exactly I would need.\n","#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n","#Person2#: That would be a definite bonus.\n","#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n","#Person2#: How can we do that?\n","#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n","#Person2#: No.\n","#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n","#Person2#: That sounds great. Thanks.\n","\n","What was going on?\n","\n"]}]},{"cell_type":"code","source":["summary = dataset['test'][example_index_to_summarize]['summary']\n","\n","inputs = tokenizer(one_shot_prompt, return_tensors='pt')\n","output = tokenizer.decode(\n","    model.generate(\n","        inputs[\"input_ids\"],\n","        max_new_tokens=50,\n","    )[0],\n","    skip_special_tokens=True\n",")\n","\n","print(dash_line)\n","print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n","print(dash_line)\n","print(f'MODEL GENERATION - ONE SHOT:\\n{output}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W-PHRNdp1J9H","executionInfo":{"status":"ok","timestamp":1715251697423,"user_tz":-330,"elapsed":5287,"user":{"displayName":"Rishita Ojha","userId":"08520112917320238697"}},"outputId":"641105ae-bd65-49fc-9856-684d46d72785"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n","\n","---------------------------------------------------------------------------------------------------\n","MODEL GENERATION - ONE SHOT:\n","#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to add a CD-ROM drive.\n"]}]},{"cell_type":"markdown","source":["**few shot inference**"],"metadata":{"id":"QeONNm-UE71J"}},{"cell_type":"code","source":["example_indices_full = [40, 80, 120, 300, 120, 140]\n","example_index_to_summarize = 301\n","\n","few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n","\n","print(few_shot_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcscHw-E1NLr","executionInfo":{"status":"ok","timestamp":1715251700626,"user_tz":-330,"elapsed":408,"user":{"displayName":"Rishita Ojha","userId":"08520112917320238697"}},"outputId":"58621058-0000-4f25-e200-7a4c825a16f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Dialogue:\n","\n","#Person1#: What time is it, Tom?\n","#Person2#: Just a minute. It's ten to nine by my watch.\n","#Person1#: Is it? I had no idea it was so late. I must be off now.\n","#Person2#: What's the hurry?\n","#Person1#: I must catch the nine-thirty train.\n","#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n","\n","What was going on?\n","#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n","\n","\n","\n","Dialogue:\n","\n","#Person1#: May, do you mind helping me prepare for the picnic?\n","#Person2#: Sure. Have you checked the weather report?\n","#Person1#: Yes. It says it will be sunny all day. No sign of rain at all. This is your father's favorite sausage. Sandwiches for you and Daniel.\n","#Person2#: No, thanks Mom. I'd like some toast and chicken wings.\n","#Person1#: Okay. Please take some fruit salad and crackers for me.\n","#Person2#: Done. Oh, don't forget to take napkins disposable plates, cups and picnic blanket.\n","#Person1#: All set. May, can you help me take all these things to the living room?\n","#Person2#: Yes, madam.\n","#Person1#: Ask Daniel to give you a hand?\n","#Person2#: No, mom, I can manage it by myself. His help just causes more trouble.\n","\n","What was going on?\n","Mom asks May to help to prepare for the picnic and May agrees.\n","\n","\n","\n","Dialogue:\n","\n","#Person1#: Hello, I bought the pendant in your shop, just before. \n","#Person2#: Yes. Thank you very much. \n","#Person1#: Now I come back to the hotel and try to show it to my friend, the pendant is broken, I'm afraid. \n","#Person2#: Oh, is it? \n","#Person1#: Would you change it to a new one? \n","#Person2#: Yes, certainly. You have the receipt? \n","#Person1#: Yes, I do. \n","#Person2#: Then would you kindly come to our shop with the receipt by 10 o'clock? We will replace it. \n","#Person1#: Thank you so much. \n","\n","What was going on?\n","#Person1# wants to change the broken pendant in #Person2#'s shop.\n","\n","\n","\n","Dialogue:\n","\n","#Person1#: I cannot imagine if Trump were to be our President again.\n","#Person2#: I am proud to say that he is our President, and I will be really happy if he could be re-elected.\n","#Person1#: You voted for him, right?\n","#Person2#: Did you vote for him, because I know that I did.\n","#Person1#: I am not sure about this.\n","#Person2#: I have nothing but faith in Trump.\n","#Person1#: What?\n","#Person2#: I am pretty sure he will make America great again!\n","#Person1#: Well, though we do need some change in this country, I don't think he is the right person.\n","#Person2#: Our country is already changing as it is.\n","#Person1#: You are right about this.\n","#Person2#: I trust that he will take good care of our country.\n","#Person1#: Well, I don't think so. I will vote for Biden anyway.\n","\n","What was going on?\n","#Person1# is crazy for Trump and voted for him. #Person2# doesn't agree with #Person1# on Trump and will vote for Biden.\n","\n","\n","\n","Dialogue:\n","\n","#Person1#: Hello, I bought the pendant in your shop, just before. \n","#Person2#: Yes. Thank you very much. \n","#Person1#: Now I come back to the hotel and try to show it to my friend, the pendant is broken, I'm afraid. \n","#Person2#: Oh, is it? \n","#Person1#: Would you change it to a new one? \n","#Person2#: Yes, certainly. You have the receipt? \n","#Person1#: Yes, I do. \n","#Person2#: Then would you kindly come to our shop with the receipt by 10 o'clock? We will replace it. \n","#Person1#: Thank you so much. \n","\n","What was going on?\n","#Person1# wants to change the broken pendant in #Person2#'s shop.\n","\n","\n","\n","Dialogue:\n","\n","#Person1#: Hello, Lin Fang!\n","#Person2#: Oh! Hi, Lucy!\n","#Person1#: What's the next lesson, Lin Fang?\n","#Person2#: English.\n","#Person1#: Oh, good! That's my favorite subject.\n","#Person2#: That's because you always find it so easy. I find it very difficult so I don't like it much.\n","#Person1#: Nancy finds English quite difficult too. But she says it's her favorite subject.\n","#Person2#: Yes, I know, and her second favorite subject is math.\n","#Person1#: Math is my worst. I don't like it. I always get the answers wrong.\n","#Person2#: So if English is your favorite subject, what's your second favorite?\n","#Person1#: PE. What about you?\n","#Person2#: I'm not sure. Both Chinese and science are my favorite subjects. I think I like Chinese a little more than science.\n","#Person1#: You are very different from Nancy. She doesn't like science at all.\n","\n","What was going on?\n","Lucy likes English and P.E. best, but Lin Fang's favorite is Chinese and Science.\n","\n","\n","\n","Dialogue:\n","\n","#Person1#: I cannot imagine if Trump were to be our President again.\n","#Person2#: I am proud to say that he is our President, and I will be really happy if he could be re-elected.\n","#Person1#: You voted for him, right?\n","#Person2#: Did you vote for him, because I know that I did.\n","#Person1#: I am not sure about this.\n","#Person2#: I have nothing but faith in Trump.\n","#Person1#: What?\n","#Person2#: I am pretty sure he will make America great again!\n","#Person1#: Well, though we do need some change in this country, I don't think he is the right person.\n","#Person2#: Our country is already changing as it is.\n","#Person1#: You are right about this.\n","#Person2#: I trust that he will take good care of our country.\n","#Person1#: Well, I don't think so. I will vote for Biden anyway.\n","\n","What was going on?\n","\n"]}]},{"cell_type":"code","source":["summary = dataset['test'][example_index_to_summarize]['summary']\n","\n","inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n","output = tokenizer.decode(\n","    model.generate(\n","        inputs[\"input_ids\"],\n","        max_new_tokens=50,\n","    )[0],\n","    skip_special_tokens=True\n",")\n","\n","print(dash_line)\n","print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n","print(dash_line)\n","print(f'MODEL GENERATION - FEW SHOT:\\n{output}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCMrF8FD1QXL","executionInfo":{"status":"ok","timestamp":1715251719630,"user_tz":-330,"elapsed":17136,"user":{"displayName":"Rishita Ojha","userId":"08520112917320238697"}},"outputId":"6933e7d7-fb5f-4144-bc1a-60ef4f66ad65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# is a crazy fan of Trump and wants him to be re-elected. #Person2# will vote for Biden.\n","\n","---------------------------------------------------------------------------------------------------\n","MODEL GENERATION - FEW SHOT:\n","#Person1 is crazy for Trump and voted for him. #Person2 is not sure about this. #Person1 is not sure about Trump and will vote for Biden.\n"]}]}]}